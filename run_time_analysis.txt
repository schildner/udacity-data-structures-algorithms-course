Task 0:
For loops for each of the two input data sets. Linear relation between input size and number of computations necessary.
Some number of computations must be performed for each row in the input files. 
Thus: O(n)

Task 1:
Same as with Task 0 - some number of computations must be performed for each row in the input files.
O(n)

Task 2:
Even though in the first for loop there is an inner for loop present, it has static size - running exactly twice.
The other for loop only loops through unique phone numbers. Worst case this will be same size as the calls list size.
Thus same as for the above tasks apply: 
O(n)

Task 3:
First for loop goes through each record in calls input list.
Conversion of the set "unique_codes" to list is presumably also O(n) with linear relationship between input size and computations needed.
Sorting the list has worst case complexity O(n log n) which is still better than O(n).
Thus worst case is still: O(n)

Task 4:
Exactly same as task 3. 
The for loops for both input data sets add up to O(n) -  some number of computations must be performed for each row in the input files.
Sorting has lower worst case complexity than O(n) so overall worst case complexity:
O(n)

All tasks:
Single line printouts have static compexity 1, need to be printed just once.
Printouts within the for loops in worst case would be same as input data size. 